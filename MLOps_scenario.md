# MLOps 시뮬레이션 시나리오

# MLOps 파이프라인 시뮬레이션 시나리오 안내서

안녕하세요! 저희는 “MLOps와 Docker”를 주제로, AI 모델이 어떻게 자동으로 개발되고 서비스되는지 보여드리는 기술 세미나를 준비했습니다.

이 문서에서는 저희가 시연할 MLOps 파이프라인이 어떤 시나리오로 동작하는지 누구나 쉽게 이해할 수 있도록 설명해 드립니다.

---

### 🎯 시나리오 목표: “AI 모델, 스스로 똑똑해지게 만들기”

저희의 목표는 AI 모델이 **과거의 데이터를 먹고 스스로 학습하고, 성능이 더 좋아지면 알아서 서비스를 교체**하는 완전 자동화 시스템을 구축하고 시연하는 것입니다.

마치 “AI 트레이너(학습 서버)”가 새로운 유망주(새 모델)를 계속 훈련시키고, “감독(추론 서버)”은 그중 최고의 선수(가장 성능 좋은 모델)를 경기에 내보내는 것과 같습니다.

### 📜 시나리오 개요

저희는 **“만약 이 시스템을 2년간 운영했다면 어땠을까?”**를 압축해서 보여주는 **시뮬레이션**을 진행합니다. 이를 위해 2년 치의 비트코인(BTC) 가격 데이터를 미리 준비했습니다.

시나리오 개요

1. **학습 서버 (AI 트레이너, 정환)**
    - 주기적으로 과거 데이터를 학습해 더 똑똑한 **‘챌린저(도전자)’ 모델**을 만들어냅니다.
    - 새로 만든 ‘챌린저’ 모델과 현재 서비스 중인 **‘챔피언’ 모델**의 성능을 공정하게 비교 평가합니다.
    - 만약 챌린저가 더 뛰어나다면, “이 모델을 새로운 챔피언으로 임명해!”라고 선언합니다.
2. **추론 서버 (경기 감독, 인혁)**
    - 고객(클라이언트)으로부터 예측 요청을 받으면, 현재 **’챔피언’으로 등록된 모델**을 사용해 예측 결과를 빠르고 안정적으로 전달하는 역할에만 집중합니다.
    - 주기적으로 누가 새로운 챔피언인지 확인하고, 챔피언이 바뀌면 조용히 다음 경기에 내보낼 선수를 교체합니다.
3. **MLflow & MinIO (전략 분석실 & 선수 숙소)**
    - **MLflow:** 모든 모델의 훈련 기록, 성능 평가 결과 등을 기록하고 관리하는 **‘전략 분석실’**입니다. 누가 챔피언이고 누가 챌린저인지 모든 정보가 이곳에 기록됩니다.
    - **MinIO:** 학습된 모델 파일과 같은 결과물들이 실제로 보관되는 **‘선수 숙소(창고)’**입니다.

---

### ⚙️ 시뮬레이션 단계별 설명

### 1단계: 최초의 챔피언 탄생

1단계

- **학습 서버**가 처음 1년 치 데이터로 `모델_v1`을 학습시킵니다. (기간은 알아서 조정)
- 이 모델이 우리의 첫 번째 **“챔피언”**이 되어 MLflow에 등록되고, **추론 서버**는 이 모델을 경기에 내보내기 시작합니다.

### 2단계: 새로운 도전자의 등장과 성능 검증

2단계

- 시간이 흘러 한 달 치 데이터가 더 쌓였다고 가정합니다.
- **학습 서버**는 1년 1개월 치 데이터로 `모델_v2`(**챌린저**)를 학습시킵니다.
- 그 후, 가장 최근 한 달 데이터를 가지고 `모델_v1`(챔피언)과 `모델_v2`(챌린저)에게 똑같은 시험을 보게 하여 **성능을 공정하게 비교**합니다.

### 3단계: 챔피언 교체 (또는 유지)

3단계

- **Case 1: 챌린저의 승리!**
    - 만약 `모델_v2`의 성능이 더 좋다면, **학습 서버**는 MLflow에 `모델_v2`를 새로운 **“챔피언”**으로 등록합니다.
    - **추론 서버**는 이 변경을 감지하고, 다음 요청부터는 `모델_v2`를 사용하여 예측 서비스를 제공합니다. (자동 교체 성공!)
- **Case 2: 챔피언의 방어!**
    - 만약 `모델_v1`의 성능이 여전히 더 좋다면, `모델_v2`는 그냥 ’유망주’로 기록에만 남고 폐기됩니다.
    - 추론 서버는 계속해서 기존의 `모델_v1`을 사용합니다.

---

이러한 시뮬레이션을 통해 저희는 실제 데이터가 실시간으로 들어오지 않아도, MLOps의 핵심 가치인 **자동화된 학습, 성능 비교, 그리고 안정적인 배포** 과정을 효과적으로 보여드릴 수 있습니다.

---

## 🎛️ 시스템 구성 요소 상세 분석 (다이어그램 기반)

위 시나리오가 동작하기 위해, 저희 시스템은 다음과 같은 서버(컴포넌트)들로 구성되어 있습니다. 이 모든 서버들은 **Docker Compose**라는 도구를 통해 하나의 시스템으로 묶여 함께 동작합니다.

### 1. FastAPI 서버 (추론 서버, 인혁)

- **역할:** AI 서비스의 “얼굴”이자 고객 응대 창구입니다.
- **주요 임무:**
    1. **예측 요청 접수:** 클라이언트로부터 “특정 날짜의 데이터를 줄 테니, 다음 시간 가격을 예측해줘” 라는 요청을 받습니다.
    2. **챔피언 모델 확인:** MLflow에 현재 “챔피언(운영용)”으로 등록된 모델이 무엇인지 확인합니다.
    3. **신속한 예측:** MinIO에서 챔피언 모델을 가져와 예측을 수행하고, 그 결과를 고객에게 빠르게 전달하는 역할에만 집중합니다.

### 2. 학습 서버 (정환)

- **역할:** 새로운 AI 모델을 끊임없이 만들어내는 “AI 트레이너”입니다.
- **주요 임무:**
    1. **주기적 학습:** 시뮬레이션된 시간의 흐름에 따라, 더 많은 과거 데이터를 포함하여 새로운 “챌린저” 모델을 학습시킵니다.
    2. **성능 비교 및 평가:** 새로 만든 챌린저 모델과 현재의 챔피언 모델을 공정한 조건에서 비교 평가합니다.
    3. **결과 보고:** 모든 학습 과정, 사용된 데이터, 파라미터, 그리고 성능 평가 결과를 MLflow에 꼼꼼히 기록합니다.
    4. **챔피언 결정:** 만약 챌린저가 더 뛰어나다면, MLflow에 해당 모델을 새로운 “챔피언”으로 승격시키는 역할을 합니다.

### 3. MLflow 서버

- **역할:** 모든 모델 개발 프로젝트를 관리하고 지휘하는 “총괄 감독” 또는 “전략 분석실”입니다.
- **주요 임무:**
    1. **실험 관리:** 모든 학습 시도(Experiment)를 기록하고 추적합니다.
    2. **모델 레지스트리:** 학습된 모든 모델의 목록(버전, 성능, 상태 등)을 관리합니다. 특히 어떤 모델이 “챔피언(Production)”이고, 어떤 모델이 “챌린저(Staging)”인지 등의 상태를 관리하는 것이 핵심입니다.
    3. **결과 시각화:** 개발자가 웹 브라우저로 접속해 여러 모델의 성능을 한눈에 비교하고 분석할 수 있는 대시보드를 제공합니다.

### 4. MinIO 서버

- **역할:** 학습된 모델 파일, 데이터셋 등 모든 결과물을 안전하게 보관하는 “거대 창고”입니다.
- **주요 임무:**
    1. **아티팩트 저장:** MLflow의 지시에 따라 학습이 완료된 AI 모델 파일(`.pkl`, `.pt` 등)과 각종 결과물을 저장합니다.
    2. **파일 제공:** 다른 서버(주로 추론 서버나 학습 서버)가 특정 모델 파일을 요청하면 안전하게 전달해줍니다.

### 5. MySQL DB 서버

- **역할:** 정형화된 데이터를 기록하는 “꼼꼼한 장부”입니다.
- **주요 임무:**
    1. **원본 데이터 저장:** 학습에 사용할 2년간의 비트코인 시세 데이터를 저장합니다.
    2. **MLflow 백엔드:** MLflow가 기록하는 수많은 실험 데이터(파라미터, 성능 수치 등 텍스트 정보)를 저장하는 데이터베이스 역할을 합니다