import os
import time
import numpy as np
import pandas as pd

from sklearn.preprocessing import StandardScaler

import torch
from torch.utils.data import DataLoader
from torch.optim import Adam
from torch.nn import MSELoss

import mlflow
from mlflow.tracking import MlflowClient
from mlflow.data.pandas_dataset import from_pandas

from module.utils import seed_everything, RMSELoss
from module.data import TimeSeriesDatasetXY
from module.model import LSTM, train_epoch, predict

print("Started")

# -------------------------------------------------------------------
# 1. MLflow ì„œë²„ ë° ì‹¤í—˜ ì„¤ì •
# -------------------------------------------------------------------
# ì¤‘ì•™ MLflow ì„œë²„ì˜ ì£¼ì†Œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. (í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ëŠ” ê²ƒì„ ê¶Œì¥)
# ì˜ˆ: mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri mysql+pymysql://... --default-artifact-root s3://...
MLFLOW_TRACKING_URI = "http://mlflow:5000" # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” MLflow ì„œë²„ì˜ IP ì£¼ì†Œ ë˜ëŠ” ë„ë©”ì¸
EXPERIMENT_NAME = "BTC Close Prediction with LSTM"
REGISTERED_MODEL_NAME = "BTC_LSTM_Production"
mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)

print("URI setted")

# ê²°ê³¼ë¥¼ ì €ì¥í•  ì‹¤í—˜(Experiment)ì˜ ì´ë¦„ì„ ì§€ì •í•©ë‹ˆë‹¤. ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±ë©ë‹ˆë‹¤.
mlflow.set_experiment(EXPERIMENT_NAME)

# -------------------------------------------------------------------
# 2. ë°ì´í„° ì¤€ë¹„
# -------------------------------------------------------------------
BASE_DATE = '2024-01-01'
DATA_PATH = './data/integreated_data.csv'
TARGET = 'btc_close'
SEED = 42

data = pd.read_csv(DATA_PATH)
data['datetime'] = pd.to_datetime(data['datetime'])

x_train = data.loc[data['datetime'] < '2024-02-01'].drop(columns=['datetime'])
y_train = data.loc[data['datetime'] < '2024-02-01', TARGET]

# ë°ì´í„° ìŠ¤ì¼€ì¼ë§
x_scaler = StandardScaler()
y_scaler = StandardScaler()

x_scaler.fit(x_train)
y_scaler.fit(y_train.values.reshape(-1, 1))

x_train_scaled = x_scaler.transform(x_train)
y_train_scaled = y_scaler.transform(y_train.values.reshape(-1, 1)).flatten()

# torch Dataset & DataLoader ê°ì²´ ìƒì„±
SEQ_LEN = 12
BATCH_SIZE = 64
LR = 0.001
EPOCH = 100

seed_everything(SEED)
train_ds = TimeSeriesDatasetXY(x_train_scaled, y_train_scaled, SEQ_LEN)
train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=False)
print("data ready")

# -------------------------------------------------------------------
# 3. MLflow ì‹¤í—˜ ì‹¤í–‰ (Run)
# -------------------------------------------------------------------
run_name = f"LSTM_HyperOpt_{time.strftime('%Y%m%d-%H%M%S')}"
# 'with' êµ¬ë¬¸ì„ ì‚¬ìš©í•˜ë©´ runì´ ëë‚  ë•Œ ìë™ìœ¼ë¡œ ì¢…ë£Œë©ë‹ˆë‹¤.
with mlflow.start_run(run_name=run_name) as run:
    run_id = run.info.run_id
    exp_id = run.info.experiment_id
    print(f"MLflow Run ID: {run_id}")

    # --- í•™ìŠµ ë°ì´í„° ê¸°ë¡ ---
    source_desc = f"Local file: {DATA_PATH}, date < 2024-02-01"
    training_dataset = from_pandas(
        x_train,
        source=source_desc,
        name="BTC Training Features"
    )
    mlflow.log_input(training_dataset, context="training")
    print("Logged Train Dataset")

    # --- íŒŒë¼ë¯¸í„°(Parameters) ê¸°ë¡ ---
    # ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.
    params = {
        "input_size": x_train_scaled.shape[1],
        "hidden_size": 64,
        "num_layers": 1,
        "seq_len": SEQ_LEN,
        "learning_rate": LR,
        "epochs": EPOCH,
        "batch_size": BATCH_SIZE
    }
    mlflow.log_params(params)
    print("Logged Parameters:", params)

    # --- ëª¨ë¸ í•™ìŠµ ---
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    seed_everything(SEED)
    model = LSTM(
        input_size=params['input_size'],
        hidden_size=params['hidden_size'],
        num_layers=params['num_layers'],
        output_size=1
    ).to(DEVICE)
    criterion = RMSELoss()
    optimizer = Adam(model.parameters(), lr=LR)

    print("ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    for epoch in range(EPOCH):
        train_epoch(
            model=model,
            data_loader=train_loader,
            criterion=criterion,
            optimizer=optimizer,
            device=DEVICE
        )

    # --- ë©”íŠ¸ë¦­(Metrics) ê¸°ë¡ ---
    # ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.
    y_pred = predict(model, train_loader, DEVICE)
    mse_loss = MSELoss()(torch.tensor(y_pred.flatten()), torch.tensor(y_train_scaled[SEQ_LEN:])).item()
    mlflow.log_metric("mse_loss", mse_loss)
    print(f"Logged Metrics: {mse_loss:.4f}")

    # --- íƒœê·¸(Tags) ê¸°ë¡ ---
    # ì‹¤í—˜ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•œ ì¶”ê°€ ì •ë³´ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.
    mlflow.set_tag("model_type", "LSTM")
    mlflow.set_tag("developer", "LJH")

    # --- ì•„í‹°íŒ©íŠ¸(Artifacts) ê¸°ë¡ ---
    # 1. í•™ìŠµëœ ëª¨ë¸ ìì²´ë¥¼ ì•„í‹°íŒ©íŠ¸ë¡œ ê¸°ë¡
    # ì´ í•¨ìˆ˜ëŠ” ëª¨ë¸, í™˜ê²½ì •ë³´(conda.yaml), ëª¨ë¸ ì‹œê·¸ë‹ˆì²˜ ë“±ì„ í•¨ê»˜ ì €ì¥í•˜ì—¬
    # ë‚˜ì¤‘ì— ì¶”ë¡  ì„œë²„ì—ì„œ ì‰½ê²Œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.
    # registered_model_nameì„ ì§€ì •í•˜ë©´ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ìë™ìœ¼ë¡œ ë“±ë¡ë©ë‹ˆë‹¤.
    
    sample_data, _ = next(iter(train_loader))
    sample_data = sample_data.numpy().astype(np.float32)

    # ğŸ’¡ PyTorch ëª¨ë¸ ê¸°ë¡!
    mlflow.pytorch.log_model(
        pytorch_model=model.cpu(),       # ì €ì¥í•  PyTorch ëª¨ë¸ ê°ì²´
        name="btc-lstm-model",  # ì•„í‹°íŒ©íŠ¸ ì €ì¥ì†Œ ë‚´ì˜ ê²½ë¡œ
        registered_model_name=REGISTERED_MODEL_NAME, # ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡í•  ì´ë¦„ (ì„ íƒì‚¬í•­)
        input_example=sample_data # ì…ë ¥ ì˜ˆì‹œ (ëª¨ë¸ì˜ ì…ë ¥ í˜•íƒœë¥¼ ì •ì˜)
    )
    
    print("\nPyTorch LSTM ëª¨ë¸ì´ MLflowì— ì„±ê³µì ìœ¼ë¡œ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # 4. (ì°¸ê³ ) ê¸°ë¡ëœ ëª¨ë¸ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸°
    # logged_model_uri = f"runs:/{run.info.run_id}/lstm-model"
    # loaded_model = mlflow.pytorch.load_model(logged_model_uri)
    # >>> ë¡œì»¬ íŒŒì¼ ê²½ë¡œë¡œ ë¶ˆëŸ¬ì˜¤ê¸°
    print("\n--- ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ ì‹œì‘ ---")
    try:
        # í•˜ë“œì½”ë”©ëœ ì‹¤í—˜ ID ëŒ€ì‹ , ë°©ê¸ˆ ì‹¤í–‰í•œ ì •ë³´ë¡œ ë™ì ìœ¼ë¡œ ê²½ë¡œ ìƒì„±
        model_path = f"./mlruns/{exp_id}/{run_id}/artifacts/btc-lstm-model"
        if os.path.exists(model_path):
            loaded_model = mlflow.pytorch.load_model(model_path)
            print("âœ… íŒŒì¼ ê²½ë¡œë¡œ ëª¨ë¸ ë¡œë“œ ì„±ê³µ:", loaded_model)
        else:
            # runs:/ ìŠ¤í‚¤ë§ˆë¡œ ë¡œë“œ ì‹œë„ (ì„œë²„ì— artifact-rootê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ëœ ê²½ìš°)
            logged_model_uri = f"runs:/{run_id}/btc-lstm-model"
            loaded_model = mlflow.pytorch.load_model(logged_model_uri)
            print("âœ… runs:/ URIë¡œ ëª¨ë¸ ë¡œë“œ ì„±ê³µ:", loaded_model)

    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("íŒ: mlflow server ì‹¤í–‰ ì‹œ --default-artifact-root ì˜µì…˜ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

print("\nMLflow Run Completed.")

# -------------------------------------------------------------------
# 4. ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬(Model Registry) ìƒí˜¸ì‘ìš© (ê°œì„ ëœ ë°©ì‹)
# -------------------------------------------------------------------
print("\nInteracting with Model Registry using Aliases...")
client = MlflowClient()

# --- ìµœì‹  ë²„ì „ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ---
# ê°€ì¥ ìµœê·¼ì— ë“±ë¡ëœ ë²„ì „ì˜ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
# search_model_versionsëŠ” ë” ìƒì„¸í•œ ê²€ìƒ‰ì„ ì œê³µí•©ë‹ˆë‹¤.
# "name='BTC_LSTM_Production'"ì€ ê²€ìƒ‰ ì¡°ê±´ì…ë‹ˆë‹¤.
latest_version_info = client.search_model_versions(f"name='{REGISTERED_MODEL_NAME}'")[-1]
latest_version = latest_version_info.version

print(f"Latest Model: {latest_version_info.name}, Version: {latest_version}, Current Aliases: {latest_version_info.aliases}")


# --- ëª¨ë¸ ë²„ì „ì— ë³„ì¹­(Alias) ì„¤ì •í•˜ê¸° ---
# 'Staging' ë‹¨ê³„ë¡œ ë³´ë‚´ëŠ” ëŒ€ì‹  'staging'ì´ë¼ëŠ” ë³„ì¹­ì„ ë¶™ì…ë‹ˆë‹¤.
# ì´ ë³„ì¹­ì€ í•´ë‹¹ ëª¨ë¸ ì´ë¦„ ë‚´ì—ì„œ ê³ ìœ í•˜ë©°, ë‹¤ë¥¸ ë²„ì „ì— ìˆë˜ 'staging' ë³„ì¹­ì€ ìë™ìœ¼ë¡œ ì´ ë²„ì „ìœ¼ë¡œ ì˜®ê²¨ì§‘ë‹ˆë‹¤.
alias_name = "staging"
client.set_registered_model_alias(
    name=REGISTERED_MODEL_NAME,
    alias=alias_name,
    version=latest_version
)
print(f"âœ… Version {latest_version}ì— '{alias_name}' ë³„ì¹­ì„ ì„±ê³µì ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.")


# --- (ì°¸ê³ ) ë³„ì¹­ìœ¼ë¡œ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ---
# ë‚˜ì¤‘ì— ì¶”ë¡  ì„œë²„ ë“±ì—ì„œ ì´ ë³„ì¹­ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
try:
    model_by_alias = client.get_model_version_by_alias(
        name=REGISTERED_MODEL_NAME,
        alias=alias_name
    )
    print(f"\n'{alias_name}' ë³„ì¹­ìœ¼ë¡œ ëª¨ë¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤: Version {model_by_alias.version}")
    # ëª¨ë¸ ë¡œë“œ: mlflow.pytorch.load_model(model_by_alias.source)
except Exception as e:
    print(f"ë³„ì¹­ìœ¼ë¡œ ëª¨ë¸ì„ ì°¾ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")