# 각 서버 역할 및 개념

# 서버 역할 및 MLOps 개념 Q&A 정리

이 문서는 MLOps 파이프라인을 구성하는 각 서버의 역할과 핵심 개념에 대해 나눈 질문과 답변을 정리한 내용입니다.

---

### Q1: 각 서버는 어떤 역할을 하나요?

A: 우리 MLOps 시스템의 각 서버를 간단한 비유와 함께 설명하면 다음과 같습니다.

- **FastAPI 서버 (추론 서버): “AI 서비스의 얼굴, 고객 응대 창구”**
    - 클라이언트의 예측 요청을 받아, 현재 서비스 중인 AI 모델의 예측 결과를 전달하는 역할을 합니다.
- **학습 서버: “AI 모델 트레이너”**
    - 주기적으로 새로운 데이터로 모델을 학습시키고, 기존 모델과 성능을 비교하여 더 나은 모델을 만들어내는 역할을 합니다.
- **MLflow 서버: “모델 개발 프로젝트의 총괄 감독”**
    - 모든 모델의 학습 과정(사용된 파라미터, 성능 등)을 기록하고, 모델의 버전과 상태(예: 운영용, 검증용)를 관리하는 중앙 관제 시스템입니다.
- **MinIO 서버: “모든 결과물을 보관하는 거대 창고”**
    - 학습된 모델 파일, 데이터셋 등 크기가 큰 모든 종류의 파일(아티팩트)을 저장하는 파일 전용 서버입니다.
- **MySQL DB 서버: “모든 정형 데이터를 기록하는 장부”**
    - 모델 학습에 필요한 원본 데이터나, MLflow가 기록하는 간단한 텍스트 정보(메타데이터)를 저장하는 전통적인 데이터베이스입니다.

---

### Q2: MLflow 서버에서는 정확히 뭘 하는 건가요?

A: MLflow 서버는 **‘AI 모델 개발의 모든 것을 기록하고 관리하는 프로젝트 관리 도구’** 입니다. 주요 기능은 크게 3가지입니다.

1. **Tracking (실험 과정 추적 및 기록):**
    - 마치 “실험 노트”처럼, 모델을 학습시킬 때마다 사용된 파라미터, 결과로 나온 성능(메트릭), 그리고 생성된 모델 파일이 MinIO의 어디에 저장되었는지 그 위치 정보(아티팩트)를 꼼꼼히 기록합니다.
2. **Model Registry (모델 버전 관리 및 상태 지정):**
    - 만들어진 모델들을 “선수 명단”처럼 등록하고 관리합니다. 여기서 각 모델 버전에 **`Production(운영용/챔피언)`**, **`Staging(검증용/챌린저)`**, **`Archived(은퇴용)`** 같은 “계급장(상태)”을 붙여주는 것이 핵심입니다. 추론 서버는 이 계급장을 보고 어떤 모델을 서비스에 사용해야 할지 판단합니다.
3. **UI (시각적 대시보드):**
    - 개발자가 웹 브라우저로 접속해 모든 실험 기록과 모델의 상태를 한눈에 보고 관리할 수 있는 화면을 제공합니다.

---

### Q3: MLflow 서버는 그냥 띄워놓기만 하면 되나요? 코드를 작성할 필요는 없나요?

A: **반은 맞고 반은 틀립니다.**

- **맞는 부분:** MLflow 서버 자체는 Docker Compose를 통해 실행시켜두기만 하면 됩니다. 서버 코드를 직접 수정할 필요는 없습니다.
- **틀린 부분:** 하지만 MLflow 서버는 수동적인 기록 보관소이므로, **학습 서버의 학습 코드 안에서 MLflow 라이브러리를 이용해 직접 명령을 내려야 합니다.** 이 코드가 없으면 MLflow 서버는 텅 빈 상태로 남게 됩니다.
    
    **학습 코드 예시:**
    
    ```python
    import mlflow
    # MLflow 서버 주소 설정mlflow.set_tracking_uri("http://mlflow-server:5000")
    # 실험 시작 선언with mlflow.start_run():
        # ... 모델 학습 진행 ...    # 학습 결과(파라미터, 성능, 모델)를 MLflow에 기록하라고 명령    mlflow.log_param("learning_rate", 0.01)
        mlflow.log_metric("accuracy", 0.92)
        mlflow.sklearn.log_model(model_object, "model")
    ```
    

---

### Q4: MySQL DB에 저장되는 ’MLflow 백엔드’란 무엇인가요?

A: 도서관에 비유할 수 있습니다.

- **MinIO:** 실제 책(모델 파일)이 보관된 **‘서고’**
- **MySQL (MLflow 백엔드):** 책의 정보(제목, 저자, 위치)가 담긴 **‘도서 검색 시스템’**

즉, MySQL은 모델 파일 자체를 저장하는 것이 아니라, 그 모델에 대한 모든 **관리 정보(메타데이터)**를 저장합니다. 여기에는 다음이 포함됩니다.

- 실험의 ID, 이름, 시간, 사용자 정보
- 학습에 사용된 파라미터와 결과로 나온 메트릭 값
- 모델의 버전, 그리고 `Production`인지 `Staging`인지 같은 상태 정보
- **가장 중요:** 모델 파일이 **MinIO의 어느 경로에 저장되어 있는지**에 대한 ‘주소’ 정보

이렇게 역할을 분리하면, 작고 정형화된 정보는 MySQL이 빠르고 효율적으로 검색/관리하고, 크고 무거운 파일은 MinIO가 안정적으로 보관할 수 있어 전체 시스템이 효율적으로 동작하게 됩니다.

---

### Q5: 클라이언트 서버는 어떤 역할을 하나요?

A: 클라이언트 서버는 최종 사용자가 AI 서비스를 직접 눈으로 보고 체험하는 **“시각화 대시보드 웹 애플리케이션”** 역할을 합니다. 단순히 API를 호출하는 것에서 나아가, 모델의 성능을 직관적으로 보여주는 중요한 임무를 수행합니다.

- **주요 임무:**
    1. **데이터 시각화:** 과거의 실제 BTC 가격 데이터(Ground Truth)를 시계열 그래프로 화면에 그려줍니다.
    2. **주기적인 예측 요청:** 매시간 정각마다 FastAPI 추론 서버에 “1시간 뒤 가격을 예측해줘”라고 자동으로 요청합니다.
    3. **예측 결과 시각화:** 응답으로 받은 예측치를 실제 가격 그래프 위에 다른 색깔의 점이나 점선으로 함께 표시합니다.
    4. **성능의 직관적 제시:** 시간이 흐름에 따라, 모델이 예측한 값(점)이 실제 가격(선)에 얼마나 근접하는지를 사용자가 눈으로 직접 확인하게 해 줌으로써 모델의 성능을 체감하게 합니다.
- **구현 기술:**
    - 이러한 대시보드는 보통 Python 기반의 **Streamlit, Gradio, Dash** 같은 데이터 과학 프레임워크나, **React/Vue.js** 같은 프론트엔드 기술을 사용하여 구현할 수 있습니다.

---

### Q6: 이 프로젝트를 실제 환경에 배포한다면 전략은 어떻게 되나요?

A: **초기/데모 단계**와 **성장/운영 단계**로 나누어 생각하는 것이 좋습니다.

### 초기/데모 단계의 배포 전략 (추천)

1. **백엔드 서버 그룹 (하나의 인스턴스):**
    - **대상:** FastAPI, 학습 서버, MLflow, MinIO, MySQL
    - **방식:** 모든 서버를 하나의 클라우드 인스턴스(가상 머신)에 올리고, **Docker Compose**를 이용해 한 번에 실행합니다. 관리가 편하고 내부 통신이 안정적입니다.
2. **클라이언트 서버 (별도의 인스턴스/플랫폼):**
    - **대상:** Streamlit 시각화 대시보드
    - **방식:** 백엔드와 분리된 다른 인스턴스나, **Streamlit Community Cloud, Heroku** 같은 플랫폼 서비스를 이용해 배포합니다. 클라이언트 코드는 백엔드 서버의 공개 IP 주소를 통해 API를 호출합니다.

이 구조는 역할 분리가 명확하고 초기 구축이 용이하여 프로젝트 시작 단계에 매우 적합합니다.

### 성장/운영 단계의 고려사항 (향후 발전 방향)

- **확장성:** 사용자가 많아지면 학습 서버와 추론 서버가 서로의 성능에 영향을 줄 수 있습니다. 이때는 **학습 서버(GPU 인스턴스)와 추론 서버(CPU 인스턴스)를 물리적으로 분리**하여 독립적으로 확장할 수 있도록 구성합니다.
- **안정성:** 하나의 서버에 장애가 나면 전체가 멈추는 문제를 해결하기 위해, **쿠버네티스(Kubernetes)** 같은 컨테이너 오케스트레이션 도구를 도입합니다. 쿠버네티스는 여러 서버를 클러스터로 묶어, 일부 서버에 문제가 생겨도 중단 없이 서비스를 운영할 수 있게 해줍니다.