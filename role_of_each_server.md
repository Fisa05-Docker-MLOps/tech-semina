# 각 서버 역할 및 개념

# 서버 역할 및 MLOps 개념 Q&A 정리

이 문서는 MLOps 파이프라인을 구성하는 각 서버의 역할과 핵심 개념에 대해 정리한 내용입니다.

---

### 1. 각 서버의 역할

- **FastAPI 서버 (추론 서버): “AI 서비스의 얼굴, 고객 응대 창구”**
    - 클라이언트의 예측 요청을 받아, **주기적으로 자동 업데이트되는 최신 모델**의 예측 결과를 전달합니다.
- **학습 서버: “AI 모델 트레이너”**
    - **매주 최신 한 달 치의 데이터로** 새로운 모델을 학습시키고, `20250531`과 같은 **날짜 기반 별칭**으로 MLflow에 등록합니다.
- **MLflow 서버: “모델 개발 프로젝트의 총괄 감독”**
    - 모든 모델의 학습 과정(사용된 파라미터, 성능 등)을 기록하고, 모델의 버전을 **날짜 기반 별칭**으로 관리하는 중앙 관제 시스템입니다.
- **MinIO 서버: “모든 결과물을 보관하는 거대 창고”**
    - 학습된 모델 파일, 데이터셋 등 크기가 큰 모든 종류의 파일(아티팩트)을 저장하는 파일 전용 서버입니다.
- **MySQL DB 서버: “모든 정형 데이터를 기록하는 장부”**
    - 모델 학습에 필요한 원본 데이터나, MLflow가 기록하는 간단한 텍스트 정보(메타데이터)를 저장하는 전통적인 데이터베이스입니다.

---

### 2. MLflow 서버에서는 정확히 뭘 하는 건가요?

MLflow 서버는 **‘AI 모델 개발의 모든 것을 기록하고 관리하는 프로젝트 관리 도구’** 입니다. 주요 기능은 크게 3가지입니다.

1.  **Tracking (실험 과정 추적 및 기록):**
    - 마치 “실험 노트”처럼, 모델을 학습시킬 때마다 사용된 파라미터, 결과로 나온 성능(메트릭), 그리고 생성된 모델 파일이 MinIO의 어디에 저장되었는지 그 위치 정보(아티팩트)를 꼼꼼히 기록합니다.
2.  **Model Registry (모델 버전 관리 및 상태 지정):**
    - 만들어진 모델들을 “선수 명단”처럼 등록하고 관리합니다. 여기서 각 모델 버전에 `Production`이나 `Staging` 같은 상태를 지정하는 대신, `20250531`과 같은 **날짜 기반 별칭(Alias)을 “생산일자 태그”처럼 붙여주는 것**이 핵심입니다. 추론 서버는 이 별칭을 기준으로 어떤 모델이 가장 최신인지 판단합니다.
3.  **UI (시각적 대시보드):**
    - 개발자가 웹 브라우저로 접속해 모든 실험 기록과 모델의 상태를 한눈에 보고 관리할 수 있는 화면을 제공합니다.

---

### 3. MLflow 서버는 그냥 띄워놓기만 하면 되나?

**반은 맞고 반은 틀립니다.**

- **맞는 부분:** MLflow 서버 자체는 Docker Compose를 통해 실행시켜두기만 하면 됩니다. 서버 코드를 직접 수정할 필요는 없습니다.
- **틀린 부분:** 하지만 MLflow 서버는 수동적인 기록 보관소이므로, **학습 서버의 학습 코드 안에서 MLflow 라이브러리를 이용해 직접 명령을 내려야 합니다.** 이 코드가 없으면 MLflow 서버는 텅 빈 상태로 남게 됩니다.
    
    **학습 코드 예시:**
    
    ```python
    import mlflow
    # MLflow 서버 주소 설정
    mlflow.set_tracking_uri("http://mlflow-server:5000")
    
    # 실험 시작 선언
    with mlflow.start_run():
        # ... 모델 학습 진행 ...
    
        # 학습 결과(파라미터, 성능, 모델)를 MLflow에 기록하라고 명령
        mlflow.log_param("learning_rate", 0.01)
        mlflow.log_metric("accuracy", 0.92)
        mlflow.sklearn.log_model(model_object, "model")
    ```
    

---

### 4. MySQL DB에 저장되는 ’MLflow 백엔드’란 무엇인가?

도서관에 비유할 수 있습니다.

- **MinIO:** 실제 책(모델 파일)이 보관된 **‘서고’**
- **MySQL (MLflow 백엔드):** 책의 정보(제목, 저자, 위치)가 담긴 **‘도서 검색 시스템’**

즉, MySQL은 모델 파일 자체를 저장하는 것이 아니라, 그 모델에 대한 모든 **관리 정보(메타데이터)** 를 저장합니다. 여기에는 다음이 포함됩니다.

- 실험의 ID, 이름, 시간, 사용자 정보
- 학습에 사용된 파라미터와 결과로 나온 메트릭 값
- 모델의 버전, 그리고 `20250531`과 같은 **별칭(Alias)** 정보
- **가장 중요:** 모델 파일이 **MinIO의 어느 경로에 저장되어 있는지**에 대한 ‘주소’ 정보

이렇게 역할을 분리하면, 작고 정형화된 정보는 MySQL이 빠르고 효율적으로 검색/관리하고, 크고 무거운 파일은 MinIO가 안정적으로 보관할 수 있어 전체 시스템이 효율적으로 동작하게 됩니다.

---

### 5. 클라이언트 서버는 어떤 역할을 하나?

A: 클라이언트 서버는 최종 사용자가 AI 서비스를 직접 눈으로 보고 체험하는 **“인터랙티브 시각화 대시보드”** 역할을 합니다. 단순히 결과를 보여주는 것을 넘어, 여러 모델의 성능을 직접 비교하고 분석할 수 있는 강력한 도구입니다.

- **주요 임무:**
    1.  **데이터 시각화:** 과거의 실제 BTC 가격 데이터를 캔들스틱 차트로 화면에 그려줍니다.
    2.  **모델 목록 제공:** MLflow 레지스트리에서 현재 등록된 모든 모델의 **날짜 기반 별칭** 목록을 가져와 사용자에게 드롭다운 메뉴로 보여줍니다.
    3.  **동적 예측 요청 및 시각화:** 사용자가 특정 모델을 선택하고 예측을 요청하면, 추론 서버에 해당 모델의 기준 날짜를 전달하여 **미래 기간의 예측값 리스트**를 받아옵니다.
    4.  **모델 성능 비교:** 받아온 예측 결과를 **실제 가격 그래프 위에 다른 색깔의 선 그래프로 함께 표시**합니다. 이 과정을 여러 모델에 대해 반복하여, 각 모델의 예측 성능을 한 화면에서 직관적으로 비교/분석할 수 있게 해줍니다.
    5. **챔피언 모델 분석 시각화:** 가장 최신의 모델로 예측한 BEST Scenario 예측치를 시각화해서 보여 한눈에 비교 분석할 수 있게 해줍니다.

- **구현 기술:**
    - 이 대시보드는 Python 기반의 **Streamlit**을 사용하여 구현되었습니다.

---

### 6. 이 프로젝트를 실제 서비스로 배포한다면 전략은 어떻게 될까?

**초기/데모 단계**와 **성장/운영 단계**로 나누어 생각하는 것이 좋습니다.

### 초기/데모 단계의 배포 전략 (현재)

1.  **백엔드 서버 그룹 (하나의 인스턴스):**
    - **대상:** FastAPI, 학습 서버, MLflow, MinIO, MySQL
    - **방식:** 모든 서버를 하나의 클라우드 인스턴스(가상 머신)에 올리고, **Docker Compose**를 이용해 한 번에 실행합니다. 관리가 편하고 내부 통신이 안정적입니다.
2.  **클라이언트 서버 (별도의 인스턴스/플랫폼):**
    - **대상:** Streamlit 시각화 대시보드
    - **방식:** 백엔드와 분리된 다른 인스턴스나, **Streamlit Community Cloud, Heroku** 같은 플랫폼 서비스를 이용해 배포합니다. 클라이언트 코드는 백엔드 서버의 공개 IP 주소를 통해 API를 호출합니다.

역할 분리가 명확하고 초기 구축이 용이합니다.

### 성장/운영 단계의 고려사항 (향후 발전 방향)

- **확장성:** 사용자가 많아지면 학습 서버와 추론 서버가 서로의 성능에 영향을 줄 수 있습니다. 이때는 **학습 서버(GPU 인스턴스)와 추론 서버(CPU 인스턴스)를 물리적으로 분리**하여 독립적으로 확장할 수 있도록 구성합니다.
- **안정성:** 하나의 서버에 장애가 나면 전체가 멈추는 문제를 해결하기 위해, **쿠버네티스(Kubernetes)** 같은 컨테이너 오케스트레이션 도구를 도입합니다. 쿠버네티스는 여러 서버를 클러스터로 묶어, 일부 서버에 문제가 생겨도 중단 없이 서비스를 운영할 수 있게 해줍니다.

---

### 7. '주기적 업데이트' 방식도 MLOps의 장점을 잘 보여주나?

**'주기적 업데이트' 방식**은 MLOps의 또 다른 핵심 가치를 더 명확하게 보여줍니다.

'챔피언 경쟁' 방식이 **'성능 중심의 안정성'** 을 강조한다면, 현재의 **'주기적 자동 업데이트'** 방식은 다음과 같은 MLOps의 중요한 장점들을 부각합니다.

1.  **훈련-배포의 자동화 (End-to-End Automation):**
    *   사람의 개입 없이 '최신 데이터 학습 → 새 모델 등록 → 서비스 교체'로 이어지는 전체 파이프라인이 자동으로 실행됩니다. 이것이야말로 MLOps의 가장 큰 장점입니다.

2.  **신속성 및 최신성 (Agility & Up-to-dateness):**
    *   매주 최신 데이터로 학습한 모델이 서비스에 반영되므로, 모델이 시장의 변화나 최신 데이터의 패턴을 놓치지 않고 빠르게 따라갑니다. "모델이 낡아서 성능이 떨어지는" 문제를 원천적으로 방지합니다.

3.  **모델의 재현성 및 버전 관리 (Reproducibility & Versioning):**
    *   모든 모델이 `20250531`과 같은 명확한 버전(별칭)으로 MLflow에 기록됩니다. 만약 최신 모델에 문제가 생기더라도, 언제든지 이전 버전으로 되돌아갈 수 있는 안정성을 확보한 것입니다.

4.  **향상된 모니터링 및 투명성 (Monitoring & Transparency):**
    *   특히 저희가 만든 **인터랙티브 시각화 대시보드**를 통해, 기술 담당자가 아니더라도 누구나 각 주차별 모델의 성능을 눈으로 직접 비교하고 평가할 수 있습니다. 이는 모델의 성능을 투명하게 공개하고, 신뢰를 구축하는 중요한 MLOps 활동입니다.

'성능이 더 좋을 때만 교체'하는 방식보다, **'매주 예측 가능한 시간에, 꾸준히 발전하는 모습을 보여주는'** 지금의 시나리오가 MLOps의 **'지속적인 통합/배포(CI/CD)'** 개념을 직관적으로 보여준다고 할 수 있습니다.
